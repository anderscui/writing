2	-1	0	0	10	I have a dataset which is a number of objects arranged in a 2-D grid. I know I have a strict ordering, increasing as you go left-to-right within each row, and increasing as top-to-bottom within each column. For example, 1 2 34 6 75 8 9Can I improve on naive sorting to sort the entire dataset linearly (as measured in comparisons)?What about for n-d datasets? Arbitrary finite datasets with a subset of comparisons known?	73	0	0	0
3	-1	0	0	5	A particular programming problem I came across recently reduces to finding hamiltonian paths in a rectangular grid that would look something like,What are some effective heuristics that could be applied to find them - and particularly, techniques to trim/discard paths along the way?Edit: Just to clarify, the edges are formed when elements are connected horizontally and vertically, but not diagonally. The problem also states that any element that is marked 0 can be used to form a path, but non 0 elements are "obstacles" that need to be avoided. could be one path, for instance. Another may be,	97	15	0	0
4	-1	0	0	10	What is the following variation on set cover known as?Given a set S, a collection C of subsets of S and a positive integer K, do there exist K sets in C such that every pair of elements of S lies in one of the selected subsets.Note: It is not hard to see that this problem is NP-Complete: Given a normal set cover problem (S, C, K), make three copies of S, say S', S'', and S''', then create your subsets as S''', |S| subsets of the form {a'} U {x in S'' | x != a} U {a'''}, |S| subsets of the form {a''} U {x in S' | x != a} U {a'''}, {a', a'' | a in C_i}. Then we can solve the set cover problem with K subsets iff we can solve the pair cover problem with K + 1 + 2 |S| subsets.This generalizes to triples, etc. I would like to be able to not waste half a page proving this, and it is probably not obvious enough to dismiss as trivial. It is certainly sufficiently useful that someone has proved it, but I have no idea who or where.Also, is there a good place to look for NP-Completeness results that are not in Garey and Johnson?	211	0	0	0
5	-1	0	0	5	Can the divide and conquer nature of the FFT be generalized to other transforms (z Transform, chirp, etc) automatically?Is there an algorithm that takes in a description of transform (I don't know what information would be needed) and can produce a fast FFT like function?	44	0	0	0
6	-1	0	0	5	Is anyone aware of any process algebraic (or related) formalisms that capture fine-grained location information? I'm familiar with ambients and bigraphs, which obviously have a location model, but what about attempts to model more concrete location information, such that the location of some agent is expressed within some (real or virtual) coordinate space?It seems to me that it would be possible to take some existing formalism and enrich it with constructs to model location at some appropriate level of abstraction, but I would hate to reinvent the wheel needlessly if this is reminiscent of previous efforts.As background, the application domain is essentially biological modeling where the traditional notions of location used in this domain to govern where interactions can occur are not fine-grained enough to capture the properties of interest.	129	0	0	0
7	-1	0	0	14	In general, the query-tape for an oracle counts towards the space-complexity of a TM. However, it seems plausible to allow a write-only oracle-tape (such as is used in L-space reductions).Is such a construction useful? Does it yield any particularly absurd results?	40	0	0	0
8	2	0	1497	2	If I understand the problem correctly (and I may not, feel free to tell me if I don't) you want to transform a 2D grid into a sorted 1D array, whereas each row and column is already sorted in the 2D grid?The first element in the list in this case has to be the top-left corner ((0,0), by definition of the problem). After this it has to either be the (1,0) or (0,1) element, as all others will be larger than these by definition.You can generalise by saying that the next smallest element in the grid is always directly below an element already used (or the edge of grid), and also to the right of an element already used (or the edge of grid), since both are defined to be smaller than it.So at each iteration you must only consider the smallest value that fulfills this requirement.You can keep the possible candidates in sorted order as you find them (no more than two will ever be made available in one iteration), and at each iteration check the new values made available (if any).If they're lower than the lowest of the previous candidates add them to the list straight away and repeat, otherwise add the lowest previous candidate and compare to the next lowest etc.Unfortunately I don't claim to be able to provide an exact complexity of this, nor do I claim it's the most efficient possible, it certainly seems better than a naive approach, and I hope I explained it well enough for you to understand.EDIT: For n-d grids like this I believe the same basic principle applies, but each iteration makes up to n new candidates available, and these candidates must be the smallest unused elements in each of n dimensions at this point.	294	0	0	0
9	6	1	625	6	Processes in Space by Luca Cardelli and Philippa Gardner is one paper in this direction. It specified a process algebra for describing the evolution of 3D structures. 	27	0	1	0
10	-1	0	0	5	There was recently a claimed proof that $P \ne NP$. Not long after its publication there were raised some issues with this proof.So ... is the proof correct or not ? (Please only answer this if you have evidence ... this question might take some time until it's answered)	48	0	2	0
11	-1	0	0	37	Functional programming has a theoretical basis in lambda calculus and combinatory logic. As someone involved with statistical computing, I find these concepts to be very useful for modeling.Is there an equivalent mathematical basis of imperative programming, or did it simply grow out of practical hardware application in machine language and the subsequent development of FORTRAN?	54	0	4	0
12	-1	0	0	25	I took a class once on Computability and Logic. The material included a correlation between complexity / computability classes (R, RE, co-RE, P, NP, Logspace, ...) and Logics (Predicate calculus, first order logic, ...).The correlation included several results in one fields, that were obtained using techniques from the other field. It was conjectured that P != NP could be attacked as a problem in Logic (by projecting the problem from the domain of complexity classes to logics).Is there a good summary of these techniques and results?	85	0	0	0
13	12	1	232	18	It's possible that you're asking about results in finite model theory (such as the characterization of P and NP in terms of various fragments of logic). The recent attempted proof of P != NP initially made heavy use of such concepts, and some good references (taken from the wiki) are Erich Gradel's review of FMT and descriptive complexityRon Fagin's article on descriptive complexity	62	0	3	0
14	-1	0	0	19	Other than going fully academic and getting a doctorate/post-doc, or going for a more or less 'standard' job in software development, what are some other career options in the full or semi theoretical C.S field?	34	0	0	0
15	-1	0	0	15	[This question has been asked on MathOverflow with no luck a month ago.]Let me first clarify my definitions. For a word $w \in \Sigma^*$, with $\Sigma =\{a_1,\ldots, a_n\}$, I define two structures:$\mathbb{N}(w) = \langle \mathbb{N}, &lt;, Q_{a_1}, \ldots, Q_{a_n} \rangle$,and the more usual word model:$\mathbb{N}^r(w) = \langle \{0, \ldots, |w|-1\}, &lt;, Q_{a_1}, \ldots, Q_{a_n} \rangle$,where $Q_{a_i} = \{p \mid w_p = a_i\}$.Then WS1S is the set of second order formulas with models of the form$\mathbb{N}(w)$, with order, and for which second order quantification islimited to finite subsets of the domain. MSO is the set of second orderformulas with models of the form $\mathbb{N}^r(w)$, with order.The usual proof that REG = WS1S proves at the same time that MSO = WS1S. Myquestion is then, for which first or second order relations can we keep thisto be true?For instance, if we add a unary predicate $E(X)$ which says that a(monadic) second order variable contains an even number of objects, we add nopower, as $E(X)$ is expressible as "there exists $X_1$ and$X_2$ that partition $X$, in such a way that if an element is in$X_i$ the next one in $X$ is in $X_j$, $i \neq j$, andthe first element of $X$ is in $X_1$ and the last is in$X_2$."Now, if we add a predicate $|X| &lt; |Y|$, then WS1S becomes undecidable(see Klaedtke &amp; Ruess, 10.1.1.7.3029), while MSO stays trivially decidable.Thank you.Edit: As a side question, ... is this question of interest? I mean, I'm no expert in the field, so I'm not sure this question is relevant.	253	0	0	0
16	10	0	697	19	See the wiki. 	3	0	1	0
17	-1	0	0	13	it is often said that when using the MD5 algorithm to sign some arbitrary information, the shared secret has to be at the end. Why?	24	0	0	0
18	10	1	928	16	In one word: No.It seems that there are some fatal flaws in Deolalikar's proposed proof. The real question now is if the "proof" has any useful ideas that can be built upon. In any case, it seems that the proof in its current form simply isn't correct, and can't be corrected either. On the other hand, Deolalikar has not given up on the proof, so I guess it's not the end of it.You can find an update here: 	78	0	1	0
19	11	0	1042	15	In short, I would say that imperative programming evolved from machine language and programming practice. On the other hand, monads provide an appropriate semantic framework for describing the semantics of imperative programming language features. The paper Notions of computation and monads by Moggi established the formal foundations. Phil Wadler popularised the idea and contributed significantly to it being the key way of incorporating imperative features into the programming language Haskell. Recent work by Plotkin and Power Notions of Computation Determine Monads goes the other way stating that some, but not all, notions of (imperative) computation actually give a monad, meaning that in a very essential way monads correspond to imperative (and other) notions of computation.	114	0	3	0
